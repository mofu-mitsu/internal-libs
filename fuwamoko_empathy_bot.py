# ğŸ”½ ğŸ“¦ Pythonã®æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from datetime import datetime, timezone
import os
import time
import random
import requests
from io import BytesIO
import filelock
import re
import logging
import cv2
import numpy as np
from urllib.parse import quote, unquote
from PIL import Image, UnidentifiedImageError, ImageFile
from copy import deepcopy
import json

# ğŸ”½ ğŸŒ± å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from dotenv import load_dotenv
from transformers import AutoModelForCausalLM, AutoTokenizer, CLIPProcessor, CLIPModel  # CLIPè¿½åŠ 
from collections import Counter
import torch
from atproto_client.models import AppBskyFeedPost
from atproto_client.exceptions import InvokeTimeoutError

# ğŸ”½ ğŸ“¡ atprotoé–¢é€£
from atproto import Client, models

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(filename='debug.log', level=logging.DEBUG, format='%(asctime)s %(message)s', encoding='utf-8')
logging.getLogger().addHandler(logging.StreamHandler())

# PILã®ã‚¨ãƒ©ãƒ¼æŠ‘åˆ¶
ImageFile.LOAD_TRUNCATED_IMAGES = True

# ğŸ”½ ğŸ§  Transformersç”¨è¨­å®šï¼ˆCLIPãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¿®æ­£ï¼‰
MODEL_NAME = "cyberagent/open-calm-small"
CLIP_MODEL_NAME = "openai/clip-vit-base-patch32"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=".cache")
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    cache_dir=".cache",
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto"  # open-calmã¯device_mapå¯¾å¿œ
)
tokenizer.pad_token = tokenizer.eos_token

# CLIPãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ­ãƒ¼ãƒ‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
clip_processor = CLIPProcessor.from_pretrained(CLIP_MODEL_NAME, cache_dir=".cache")
clip_model = CLIPModel.from_pretrained(
    CLIP_MODEL_NAME,
    cache_dir=".cache",
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
).to(device)  # ãƒ‡ãƒã‚¤ã‚¹æ˜ç¤ºæŒ‡å®š
clip_model.eval()
logging.info(f"ğŸŸ¢ CLIPãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {CLIP_MODEL_NAME}, ãƒ‡ãƒã‚¤ã‚¹: {device}")

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
HANDLE = os.environ.get("HANDLE")
APP_PASSWORD = os.environ.get("APP_PASSWORD")
SESSION_FILE = "session_string.txt"
FUWAMOKO_FILE = "fuwamoko_empathy_uris.txt"
FUWAMOKO_LOCK = "fuwamoko_empathy_uris.lock"
REPLIED_FILE = "replied_uris.txt"
REPLIED_LOCK = "replied_uris.lock"
# Gistè¨­å®šï¼ˆFeed Botã‹ã‚‰ã‚³ãƒ”ãƒ¼ï¼‰
GIST_RAW_URL_URIS = "https://gist.githubusercontent.com/mofu-mitsu/c16e8c8c997186319763f0e03f3cff8b/raw/replied_uris.json"
GIST_TOKEN = os.environ.get("GIST_TOKEN")  # .envã«è¿½åŠ ãŒå¿…è¦

# ğŸ”½ ãƒ†ãƒ³ãƒ—ãƒ¬ä¿è­·ï¼ˆãƒãƒ£ãƒƒãƒ”ãƒ¼æ†²ç« ï¼‰
LOCK_TEMPLATES = True
ORIGINAL_TEMPLATES = {
    "NORMAL_TEMPLATES_JP": [
        "ã†ã‚“ã†ã‚“ã€ã‹ã‚ã„ã„ã­ï¼ç™’ã•ã‚ŒãŸã‚ˆğŸ¾ğŸ’–",
        "ã‚ˆã‹ã£ãŸã­ã€œï¼ãµã‚ãµã‚ã ã­ğŸŒ¸ğŸ§¸",
        "ãˆã¸ã£ã€ãƒ¢ãƒ•ãƒ¢ãƒ•ã§ç™’ã—MAXï¼ğŸ’",
        "ã†ã‚ã£ï¼å¯æ„›ã™ãã‚‹ã‚ˆğŸ¾ğŸŒ·",
        "ãµã‚ãµã‚ã ã­ã€å…ƒæ°—å‡ºãŸï¼ğŸ’«ğŸ§¸",
        "ãµã‚“ã‚ã‚Šå„ªã—ã„æ°—æŒã¡ã«ãªã£ãŸã€œâ˜ï¸ğŸ’•",
        "ãã‚…ã‚“â€¦ã‹ã‚ã„ã™ãã¦ã¨ã‚ã‘ãã†ğŸ¥¹ğŸ§¸",
        "ã»ã£ã“ã‚Šã—ã¡ã‚ƒã£ãŸã€œãµã‚ãµã‚æœ€é«˜ã€œğŸ§¸âœ¨",
        "ãã‚…ã£ã¦ã—ãŸããªã‚‹â€¦ç™’ã•ã‚Œã‚‹ã­ã€œğŸ’–ğŸ¾",
        "ã‚‚ã†â€¦å°Šã„â€¦ç™’ã—ãŒè©°ã¾ã£ã¦ã‚‹ã‚ˆã€œğŸŒ¸ğŸŒ¸"
    ],
    "SHONBORI_TEMPLATES_JP": [
        "ãã£ã‹â€¦ãã‚…ãƒ¼ã£ã¦ã—ã¦ã‚ã’ã‚‹ã­ğŸ¾ğŸ’•",
        "å…ƒæ°—å‡ºã—ã¦ã­ã€ãµã‚ã‚‚ã“ãƒ‘ãƒ¯ãƒ¼é€ã‚‹ã‚ˆï¼ğŸ§¸âœ¨",
        "ã¤ã‚‰ã„ã¨ãã“ãã€ãµã‚ãµã‚ã«åŒ…ã¾ã‚Œã¦â€¦ğŸ°â˜ï¸",
        "ç„¡ç†ã—ãªã„ã§ã­ã€ãã£ã¨å¯„ã‚Šæ·»ã†ã‚ˆğŸ§¸ğŸŒ¸"
    ],
    "MOGUMOGU_TEMPLATES_JP": [
        "ã†ãƒ¼ã‚“â€¦ã“ã‚Œã¯ç™’ã—ã‚ˆã‚Šç¾å‘³ã—ãã†ï¼ŸğŸ¾ğŸ’­",
        "ã‚‚ãã‚‚ãã—ã¦ã‚‹ã‘ã©â€¦ãµã‚ã‚‚ã“ã˜ã‚ƒãªã„ã‹ãªï¼ŸğŸ¤”",
        "ã¿ã‚Šã‚“ã¦ã‚ƒã€ãŠè…¹ç©ºã„ã¦ãã¡ã‚ƒã£ãŸâ€¦é£Ÿãƒ¬ãƒï¼ŸğŸ½ï¸ğŸ’¬"
    ],
    "NORMAL_TEMPLATES_EN": [
        "Wow, so cute! Feels good~ ğŸ¾ğŸ’–",
        "Nice! So fluffy~ ğŸŒ¸ğŸ§¸",
        "Great! Healing vibes! ğŸ’",
        "So adorable, it warmed my heart! ğŸ’–",
        "Aww, I feel hugged just looking at it~ ğŸ§¸ğŸ’•",
        "Too cute! Iâ€™m melting! â˜ï¸ğŸ’",
        "Thatâ€™s pure fluff happiness~ ğŸ¾ğŸŒ¸",
        "Soft, sweet, and so healing~ âœ¨ğŸ§¸",
        "It made my heart smile! ğŸ’«ğŸ’–",
        "Amazing! Thanks for the fluff! ğŸ¾ğŸŒ·"
    ],
    "MOGUMOGU_TEMPLATES_EN": [
        "Hmmm... looks tasty, but maybe not so fluffy? ğŸ¾ğŸ’­",
        "So yummy-looking... but is this a snack or a friend? ğŸ¤”ğŸ½ï¸",
        "This might be food, not a fluffy cutie... ğŸ½ï¸ğŸ’­",
        "Adorable! But maybe not a fluffy buddy? ğŸ‘ğŸ’¬"
    ],
    "COSMETICS_TEMPLATES_JP": {
        "ãƒªãƒƒãƒ—": ["ã“ã®ãƒªãƒƒãƒ—å¯æ„›ã„ã€œğŸ’„ğŸ’–", "è‰²å‘³ãŒç´ æ•µã™ãã¦ã†ã£ã¨ã‚Šã—ã¡ã‚ƒã†ğŸ’‹"],
        "é¦™æ°´": ["ã“ã®é¦™ã‚Šã€çµ¶å¯¾ãµã‚ã‚‚ã“ã ã‚ˆã­ğŸŒ¸", "ã„ã„åŒ‚ã„ã€œï¼ğŸ’•"],
        "ãƒã‚¤ãƒ«": ["ãã®ãƒã‚¤ãƒ«ã€ã‚­ãƒ©ã‚­ãƒ©ã—ã¦ã¦æœ€é«˜ğŸ’…âœ¨", "ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼ã§ç´ æ•µã€œğŸ’–"]
    },
    "COSMETICS_TEMPLATES_EN": {
        "lip": ["That lipstick is so cute~ ğŸ’„ğŸ’–", "The color is dreamy, Iâ€™m in love ğŸ’‹"],
        "perfume": ["I bet that perfume smells fluffy and sweet ğŸŒ¸", "I can almost smell it~ so lovely! ğŸŒ¼"],
        "nail": ["That nail art is sparkly and perfect ğŸ’…âœ¨", "Fluffy colors make it so pretty ğŸ’–"]
    },
    "CHARACTER_TEMPLATES_JP": {
        "ã‚¢ãƒ‹ãƒ¡": ["ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ãŒãƒ¢ãƒ•ãƒ¢ãƒ•ï¼ğŸ’•", "ã¾ã‚‹ã§å¤¢ã®ä¸–ç•Œã®ä½äººğŸŒŸ"],
        "æ¼«ç”»": ["ã‚³ãƒã‹ã‚‰é£›ã³å‡ºã—ã¦ããŸã¿ãŸã„ï¼ğŸ“–âœ¨", "ã“ã®ã‚¿ãƒƒãƒã€ã‚ã¡ã‚ƒå¥½ã¿â€¦ï¼ğŸ’˜"],
        "ã‚¤ãƒ©ã‚¹ãƒˆ": ["ç·šã®å„ªã—ã•ã«ç™’ã•ã‚Œã‚‹â€¦ğŸ–‹ï¸ğŸŒ¼", "è‰²ã¥ã‹ã„ãŒã»ã‚“ã¨ç´ æ•µğŸ’–"],
        "ä¸€æ¬¡å‰µä½œ": ["ã‚ªãƒªã‚­ãƒ£ãƒ©å°Šã„â€¦ğŸ¥ºâœ¨", "ã“ã®å­ã ã‘ã®ä¸–ç•Œè¦³ãŒã‚ã‚‹ã­ğŸ’–"],
        "äºŒæ¬¡å‰µä½œ": ["ã“ã®è§£é‡ˆã€å¤©æ‰ã™ãã‚‹â€¦ï¼ğŸ™Œ", "åŸä½œæ„›ãŒä¼ã‚ã£ã¦ãã‚‹ã‚ˆâœ¨"]
    },
    "CHARACTER_TEMPLATES_EN": {
        "anime": ["That anime character looks so fluffy! ğŸ’•", "Like someone straight out of a dream world~ ğŸŒŸ"],
        "manga": ["They look like they just stepped out of a manga panel! ğŸ“–âœ¨", "I love the vibe of this linework! ğŸ’˜"],
        "illustration": ["The softness in these lines is so comforting~ ğŸ–‹ï¸ğŸŒ¼", "The colors are simply beautiful! ğŸ’–"],
        "oc": ["Your OC is preciousâ€¦ ğŸ¥ºâœ¨", "They have such a unique and magical world of their own ğŸ’–"],
        "fanart": ["Your interpretation is genius! ğŸ™Œ", "I can feel your love for the original work âœ¨"]
    }
}

# ğŸ”½ ã‚°ãƒ­ãƒ¼ãƒãƒ«è¾æ›¸åˆæœŸåŒ–
try:
    _ = globals()["EMOTION_TAGS"]
except KeyError:
    logging.error("âš ï¸ EMOTION_TAGSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["EMOTION_TAGS"] = {
        "fuwamoko": ["ãµã‚ãµã‚", "ã‚‚ã“ã‚‚ã“", "ã‚‚ãµã‚‚ãµ", "fluffy", "fluff", "fluffball", "ãµã‚ã‚‚ã“",
                     "ã½ã‚ˆã½ã‚ˆ", "ã‚„ã‚ã‚„ã‚", "ãã‚…ã‚‹ãã‚…ã‚‹", "ã½ãµã½ãµ", "ãµã‚ã‚‚ãµ", "é›²"],
        "neutral": ["ã‹ã‚ã„ã„", "cute", "adorable", "æ„›ã—ã„"],
        "shonbori": ["ã—ã‚‡ã‚“ã¼ã‚Š", "ã¤ã‚‰ã„", "ã‹ãªã—ã„", "ã•ã³ã—ã„", "ç–²ã‚ŒãŸ", "ã¸ã“ã‚“ã ", "æ³£ããã†"],
        "food_ng": ["è‚‰", "ã”é£¯", "é£¯", "ãƒ©ãƒ³ãƒ", "ãƒ‡ã‚£ãƒŠãƒ¼", "ãƒ¢ãƒ¼ãƒ‹ãƒ³ã‚°", "ã”ã¯ã‚“", "åµ", "ãŸã¾ã”", "ãŠã«ãã‚Š",
                    "ãŠã„ã—ã„", "ã†ã¾ã„", "ç¾å‘³", "ã„ãŸã ãã¾ã™", "ãŸã¹ãŸ", "é£Ÿ", "ã”ã¡ãã†", "ã”é¦³èµ°",
                    "ã¾ãã‚", "åˆºèº«", "ãƒãƒ¼ã‚º", "ã‚¹ãƒŠãƒƒã‚¯", "yummy", "delicious", "ã‚¹ãƒ¼ãƒ—",
                    "å‘³å™Œæ±", "ã‚«ãƒ«ãƒœãƒŠãƒ¼ãƒ©", "é‹", "éºº", "ãƒ‘ãƒ³", "ãƒˆãƒ¼ã‚¹ãƒˆ", "è±†è…",
                    "ã‚«ãƒ•ã‚§", "ã‚¸ãƒ¥ãƒ¼ã‚¹", "ãƒŸãƒ«ã‚¯", "ãƒ‰ãƒªãƒ³ã‚¯", "ãŠã‚„ã¤", "é£Ÿäº‹", "æœé£Ÿ", "å¤•é£Ÿ", "æ˜¼é£Ÿ"],
        "nsfw_ng": ["é…’", "ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«", "ãƒ“ãƒ¼ãƒ«", "ãƒ¯ã‚¤ãƒ³", "é…ãƒã‚¤", "ã‚«ã‚¯ãƒ†ãƒ«", "ãƒã‚¤ãƒœãƒ¼ãƒ«", "æ¢…é…’",
                    "soft core", "NSFW", "è‚Œè‰²", "ä¸‹ç€", "è‚Œè¦‹ã›", "éœ²å‡º",
                    "è‚Œãƒ•ã‚§ãƒ", "soft skin", "fetish", "nude", "naked", "lewd", "18+", "sex", "uncensored"],
        "safe_cosmetics": ["ãƒªãƒƒãƒ—", "é¦™æ°´", "ãƒã‚¤ãƒ«", "lip", "perfume", "nail"]
                    
    }

try:
    _ = globals()["SAFE_CHARACTER"]
except KeyError:
    logging.error("âš ï¸ SAFE_CHARACTERæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["SAFE_CHARACTER"] = {
        "ã‚¢ãƒ‹ãƒ¡": ["ã‚¢ãƒ‹ãƒ¡", "anime", "anime art", "ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©"],
        "æ¼«ç”»": ["æ¼«ç”»", "ãƒãƒ³ã‚¬", "manga", "comic"],
        "ã‚¤ãƒ©ã‚¹ãƒˆ": ["ã‚¤ãƒ©ã‚¹ãƒˆ", "illustration", "drawing", "ã‚¹ã‚±ãƒƒãƒ", "art", "è½æ›¸ã"],
        "ä¸€æ¬¡å‰µä½œ": ["ä¸€æ¬¡å‰µä½œ", "ã‚ªãƒªã‚­ãƒ£ãƒ©", "ã‚ªãƒªã‚¸ãƒŠãƒ«", "oc", "original character", "my oc"],
        "äºŒæ¬¡å‰µä½œ": ["äºŒæ¬¡å‰µä½œ", "fanart", "fan art", "FA", "fandom art", "åŸä½œã‚­ãƒ£ãƒ©", "åŸä½œå†ç¾", "æ¨ã—ã‚­ãƒ£ãƒ©"]
    }

try:
    _ = globals()["GENERAL_TAGS"]
except KeyError:
    logging.error("âš ï¸ GENERAL_TAGSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["GENERAL_TAGS"] = ["ã‚­ãƒ£ãƒ©", "æ¨ã—"]

try:
    _ = globals()["HIGH_RISK_WORDS"]
except KeyError:
    logging.error("âš ï¸ HIGH_RISK_WORDSæœªå®šç¾©ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æ³¨å…¥ã—ã¾ã™ã€‚")
    globals()["HIGH_RISK_WORDS"] = ["ã‚‚ã¡ã‚‚ã¡", "ã·ã«ã·ã«", "ã·ã‚ˆã·ã‚ˆ", "ã‚„ã‚ã‚‰ã‹ã„", "ã‚€ã«ã‚…ã‚€ã«ã‚…", "ã‚¨ãƒ­", "ãˆã£ã¡"]

# å„ªå…ˆé †ä½
PRIORITY_ORDER = ["äºŒæ¬¡å‰µä½œ", "ä¸€æ¬¡å‰µä½œ", "ã‚¢ãƒ‹ãƒ¡", "æ¼«ç”»", "ã‚¤ãƒ©ã‚¹ãƒˆ"]

# ãƒ†ãƒ³ãƒ—ãƒ¬ç›£æŸ»ãƒ­ã‚°
TEMPLATE_AUDIT_LOG = "template_audit_log.txt"

def audit_templates_changes(old, new):
    try:
        if old != new:
            with open(TEMPLATE_AUDIT_LOG, "a", encoding="utf-8") as f:
                f.write(json.dumps({
                    "timestamp": datetime.now().isoformat(),
                    "before": old,
                    "after": new
                }, ensure_ascii=False, indent=2) + "\n")
            logging.warning("âš ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬å¤‰æ›´æ¤œå‡º")
    except Exception as e:
        logging.error(f"âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ç›£æŸ»ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def check_template_integrity(templates):
    if not LOCK_TEMPLATES:
        logging.warning("âš ï¸ LOCK_TEMPLATESç„¡åŠ¹ã€æ”¹å¤‰ãƒªã‚¹ã‚¯")
        return False
    for key in ORIGINAL_TEMPLATES:
        if templates.get(key) != ORIGINAL_TEMPLATES[key]:
            logging.error(f"âš ï¸ {key} æ”¹å¤‰æ¤œå‡ºã€å¾©å…ƒæ¨å¥¨")
            return False
    return True

def auto_revert_templates(templates):
    if LOCK_TEMPLATES:
        for key in ORIGINAL_TEMPLATES:
            templates[key] = deepcopy(ORIGINAL_TEMPLATES[key])
        logging.info("âœ… ãƒ†ãƒ³ãƒ—ãƒ¬å¾©å…ƒå®Œäº†")
        return templates
    return templates

fuwamoko_tone_map = [
    ("ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™", "ã‚ã‚ŠãŒã¨ğŸ°ğŸ’“"),
    ("ã‚ã‚ŠãŒã¨ã†", "ã‚ã‚ŠãŒã¨â™ª"),
    ("ã§ã™ã­", "ã ã­ã€œâœ¨"),
    ("ã§ã™ã‚ˆ", "ã ã‚ˆâ™¡"),
    ("ã§ã™", "ã ã‚ˆâ™¡"),
    ("ã¾ã™", "ã™ã‚‹ã‚ˆâ™ª"),
    ("ã¾ã—ãŸ", "ã—ãŸã‚ˆã€œğŸ’–"),
]

def apply_fuwamoko_tone(reply):
    for formal, soft in fuwamoko_tone_map:
        reply = reply.replace(formal, soft)
    reply = reply.replace(r'(ğŸ°ğŸ’“)\.', r'\1')  # å¥ç‚¹ã¨çµµæ–‡å­—ã®ç•°å¸¸ä¿®æ­£
    reply = re.sub(r'([â™ªâ™¡])\s*\.', r'\1', reply)  # â™ªã€‚ã‚’ä¿®æ­£
    return reply

def is_fluffy_color(r, g, b, bright_colors):
    logging.debug(f"ğŸ§ª è‰²åˆ¤å®š: RGB=({r}, {g}, {b})")
    hsv = cv2.cvtColor(np.array([[[r, g, b]]], dtype=np.uint8), cv2.COLOR_RGB2HSV)[0][0]
    h, s, v = hsv
    logging.debug(f"HSV=({h}, {s}, {v})")

    # é£Ÿå“è‰²ç¯„å›²ï¼ˆãƒãƒ /åµ/ãŠã«ãã‚Š/è±†è…ï¼‹ãƒ‘ãƒ³è¿½åŠ ï¼‰
    if ((150 <= r <= 200 and 150 <= g <= 200 and 150 <= b <= 200) or  # ãƒãƒ /åµ
        (220 <= r <= 250 and 220 <= g <= 250 and 210 <= b <= 230) or  # ãŠã«ãã‚Š
        (230 <= r <= 255 and 200 <= g <= 230 and 130 <= b <= 160) or  # è±†è…
        (r == 255 and g == 255 and b == 255) or                      # ç´”ç™½
        (160 <= r <= 241 and 91 <= g <= 192 and 3 <= b <= 43) or     # ãƒ‘ãƒ³ï¼ˆ#AE5B05ï½#F1C02B, #3E0503ï¼‰
        (r > 150 and g < 100 and b < 50 and v > 100)):               # ç„¦ã’ãŸãƒ‘ãƒ³ï¼ˆèŒ¶è‰²ç³»ï¼‰
        logging.debug("é£Ÿå“è‰²ï¼ˆãƒãƒ /åµ/ãŠã«ãã‚Š/è±†è…/ãƒ‘ãƒ³/ç„¦ã’ï¼‰æ¤œå‡ºã€ãµã‚ã‚‚ã“ã¨ã¿ãªã•ãªã„")
        return False

    # ç™½ç³»ï¼ˆæ˜ã‚‹ã•v > 130ã€å˜è‰²é–¾å€¤10ï¼‰
    if r > 180 and g > 180 and b > 180 and v > 130:
        if bright_colors and len(bright_colors) > 0:
            colors = np.array(bright_colors)
            if np.std(colors, axis=0).max() < 10:
                logging.debug("å˜è‰²ç™½ç³»ã€ãµã‚ã‚‚ã“ã¨ã¿ãªã•ãªã„")
                return False
        logging.debug("ç™½ç³»æ¤œå‡ºï¼ˆæ˜ã‚‹ã•OKã€ãƒ”ãƒ³ã‚¯å¯„ã‚Šå«ã‚€ï¼‰")
        return True

    # ãƒ”ãƒ³ã‚¯ç³»ï¼ˆæ¡ƒèŠ±å„ªå…ˆï¼‰
    if (r > 200 and g < 170 and b > 170 and v > 130) or \
       (220 <= r <= 240 and 220 <= g <= 240 and 230 <= b <= 250):  # #232, 236, 247 å¯¾å¿œ
        logging.debug("ãƒ”ãƒ³ã‚¯ç³»æ¤œå‡ºï¼ˆæ¡ƒèŠ±å„ªå…ˆã€æ˜ã‚‹ã•OKï¼‰")
        return True

    # ã‚¯ãƒªãƒ¼ãƒ è‰²
    if r > 220 and g > 210 and b > 170 and v > 130:
        logging.debug("ã‚¯ãƒªãƒ¼ãƒ è‰²æ¤œå‡ºï¼ˆåºƒã‚ï¼‰")
        return True

    # ãƒ‘ã‚¹ãƒ†ãƒ«ãƒ‘ãƒ¼ãƒ—ãƒ«
    if (r > 220 and g > 210 and b > 240 and abs(r - b) < 60 and v > 130) or \
       (220 <= h <= 300 and s < 50 and v > 130):  # #F6DAF6, #E9DAF9 å¯¾å¿œ
        logging.debug("ãƒ‘ã‚¹ãƒ†ãƒ«ãƒ‘ãƒ¼ãƒ—ãƒ«æ¤œå‡ºï¼ˆæ˜ã‚‹ã•OKï¼‰")
        return True

    # ç™½ç°ãƒ”ãƒ³ã‚¯ç³»
    if r > 200 and g > 180 and b > 200 and v > 130:
        logging.debug("ãµã‚ã‚‚ã“ç™½ç°ãƒ”ãƒ³ã‚¯æ¤œå‡ºï¼ˆæ¡ƒèŠ±å¯¾å¿œï¼‰")
        return True

    # ç™½ç°ç³»
    if 200 <= r <= 255 and 200 <= g <= 240 and 200 <= b <= 255 and abs(r - g) < 30 and abs(r - b) < 30 and v > 130:
        logging.debug("ç™½ç°ãµã‚ã‚‚ã“ã‚«ãƒ©ãƒ¼ï¼ˆæŸ”ã‚‰ã‹ç³»ï¼‰")
        return True

    if 200 <= h <= 300 and s < 80 and v > 130:
        logging.debug("ãƒ‘ã‚¹ãƒ†ãƒ«ç³»ç´«ï½ãƒ”ãƒ³ã‚¯æ¤œå‡ºï¼ˆæ˜ã‚‹ã•OKï¼‰")
        return True

    if 190 <= h <= 260 and s < 100 and v > 130:
        logging.debug("å¤œç©ºãƒ‘ã‚¹ãƒ†ãƒ«ç´«æ¤œå‡ºï¼ˆåºƒã‚ã€æ˜ã‚‹ã•OKï¼‰")
        return True

    return False

def clean_output(text):
    # é¡”æ–‡å­—ã‚’ä¿è­·ï¼ˆä¾‹: (*.*), (*^Ï‰^*) ï¼‰
    face_pattern = r'\(\*[^\)]+\*\)'
    face_placeholders = []
    for i, face in enumerate(re.findall(face_pattern, text)):
        placeholder = f"__FACE_{i}__"
        face_placeholders.append((placeholder, face))
        text = text.replace(face, placeholder)
        
    text = re.sub(r'[\r\n]+', ' ', text)
    text = re.sub(r'\s{2,}', ' ', text)
    text = re.sub(r'!{2,}', 'ï¼', text)
    text = re.sub(r'^(çŸ­ãã€ãµã‚ã‚‚ã“ãªè¿”äº‹ã‚’ã—ã¦ã­ã€‚|.*â†’\s*|å¯’ã„ã€œ\s*)', '', text)  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„çŸ¢å°ã‚’å‰Šé™¤
    text = re.sub(r'^ã‚‚ãµã‚‚ãµã§ã‚ã£ãŸã¾ã‚ã€œâ™¡\s*', '', text)  # ãƒ†ãƒ³ãƒ—ãƒ¬å‰Šé™¤
    text = re.sub(r'^[^ã€‚ï¼ï¼Ÿ\n]{1,10}ã£ã¦ç™’ã•ã‚Œã‚‹ã‚ˆã­ã€œ\s*', '', text)  # ãƒ†ãƒ³ãƒ—ãƒ¬å‰Šé™¤
    text = re.sub(r'[^\w\sã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯ã€‚ã€ï¼ï¼Ÿ!?â™¡\w\(\)ã€Œã€â™ªã€œãƒ¼â€¦ç¬‘]+', '', text)
    text = re.sub(r"ã€‚([ğŸ¾ğŸŒ¸ğŸ§¸âœ¨ğŸ’•â™¡â™ªï½ğŸ’«ï¼]+)", r"\1", text)
    text = re.sub(r'([ã€‚ã€ï¼ï¼Ÿ])\s*ğŸ’–', r'\1ğŸ’–', text)
    text = re.sub(r'[ã€‚ã€ï¼ï¼Ÿ]{2,}', lambda m: m.group(0)[0], text)
    # é¡”æ–‡å­—ã‚’å¾©å…ƒ
    for placeholder, face in face_placeholders:
        text = text.replace(placeholder, face)
    return text.strip()

def open_calm_reply(image_url, text="", context="ãµã‚ã‚‚ã“å…±æ„Ÿ", lang="ja"):
    NG_WORDS = globals()["EMOTION_TAGS"].get("nsfw_ng", [])
    NG_PHRASES = [
        r"(?:æŠ•ç¨¿|ãƒ¦ãƒ¼ã‚¶ãƒ¼|ä¾‹æ–‡|ãƒã‚¹ã‚¯ãƒƒãƒˆ|ãƒã‚¹ã‚±ãƒƒãƒˆ|ãƒ•ã‚©ãƒ¼ãƒ©ãƒ |è¿”äº‹|ä¼šè©±|å…±æ„Ÿ)",
        r"(?:ç™’ã—ç³»ã®ãµã‚ã‚‚ã“ãƒã‚¹ã‚³ãƒƒãƒˆ|æŠ•ç¨¿å†…å®¹ã«å¯¾ã—ã¦)",
        r"[â– #]{2,}",
        r"!{5,}", r"\?{5,}", r"[!ï¼Ÿ]{5,}",
        r"(?:(ãµã‚|ã‚‚ã“|ã‚‚ã¡|ã½ã“)\1{3,})",
        r"\bã‚‚ã£ã¡ã‚Š\b", r"\bã‚‚ã¡ã‚‚ã¡\b",
        r"[â™ª~]{2,}",
        r"(#\w+){3,}",
        r"^[^\w\s]+$", r"(\w+\s*,){3,}", r"[\*:\.]{2,}",
        r"\bç„¡ç†\b", r"\bç„¡ç†ã§ã™\b", r"\bãƒ€ãƒ¡\b", r"\bå«Œã„\b", r"\bãã‚‰ã„\b",
        r"\bè·é›¢\b", r"\bä»˜ãåˆãˆ\b", r"\bé–¢ä¿‚ãªã„\b", r"\bèˆˆå‘³ãªã„\b", r"\bã‚„ã‚\b",
        r"(ã½ã£ã½|ã‚‚ã‚‚ã½ã£ã½|ãµã‚ã‚‚ã‚‚ã½ã£ã½)",
        r"[ã-ã‚“]{5,}",  # ã²ã‚‰ãŒãª5æ–‡å­—ä»¥ä¸Š
        r"(ã½ã£ã“ã‚Š|ãŠè…¹ã½ã£ã“ã‚Š|ä½“å‹|å¤ªã£ãŸ|ä½“é‡|ãƒ€ã‚¤ã‚¨ãƒƒãƒˆ)",
        r"\bä»²è‰¯ãã§ããªã„\b", r"\bè‹¦æ‰‹\b", r"\bã‚­ãƒ¢\b", r"\bç¸ãŒãªã„\b",
        r"\bãƒã‚«\b", r"\bé¦¬é¹¿\b", r"\bã‚¢ãƒ›\b", r"\bãã‚‚\b", r"\bé§„ç›®\b",
        r"\bçŠ¬\b", r"\bã‚ã‚“ã¡ã‚ƒã‚“\b", r"\bçŒ«\b", r"\bçŒ«ã¡ã‚ƒã‚“\b",  # å‹•ç‰©åNG
        r"\bã‚¦ã‚µã‚®\b", r"\bç¾Š\b", r"\bãƒãƒ ã‚¹ã‚¿ãƒ¼\b", r"\bã‚¯ãƒ\b",
        r"\bãã‚“ã“\b", r"\bãµãã‚“ã“\b", r"\bã¦ã„ã\b", r"\bã„ãã™ã‚‹\b"  # å¤‰ãªé€ èªNG
    ]
    SEASONAL_WORDS_BLACKLIST = ["å¯’ã„", "ã‚ã£ãŸã¾ã‚", "å‡ãˆã‚‹", "å†·ãŸã„"]

    templates = deepcopy(ORIGINAL_TEMPLATES)
    if not check_template_integrity(templates):
        templates = auto_revert_templates(templates)
    audit_templates_changes(ORIGINAL_TEMPLATES, templates)

    NORMAL_TEMPLATES_JP = templates["NORMAL_TEMPLATES_JP"]
    SHONBORI_TEMPLATES_JP = templates["SHONBORI_TEMPLATES_JP"]
    MOGUMOGU_TEMPLATES_JP = templates["MOGUMOGU_TEMPLATES_JP"]
    NORMAL_TEMPLATES_EN = templates["NORMAL_TEMPLATES_EN"]
    MOGUMOGU_TEMPLATES_EN = templates["MOGUMOGU_TEMPLATES_EN"]
    COSMETICS_TEMPLATES_JP = templates["COSMETICS_TEMPLATES_JP"]
    COSMETICS_TEMPLATES_EN = templates["COSMETICS_TEMPLATES_EN"]
    CHARACTER_TEMPLATES_JP = templates["CHARACTER_TEMPLATES_JP"]
    CHARACTER_TEMPLATES_EN = templates["CHARACTER_TEMPLATES_EN"]

    detected_tags = []
    for tag, words in globals()["EMOTION_TAGS"].items():
        if any(word in text.lower() for word in words):
            detected_tags.append(tag)

    if "food_ng" in detected_tags or any(word.lower() in text.lower() for word in NG_WORDS) or "ãƒ‘ãƒ³" in text.lower():
        logging.debug(f"ğŸ½ï¸ NGãƒ¯ãƒ¼ãƒ‰/é£Ÿäº‹æ¤œå‡º: {text[:60]}")
        return random.choice(MOGUMOGU_TEMPLATES_JP) if lang == "ja" else random.choice(MOGUMOGU_TEMPLATES_EN)
    elif "shonbori" in detected_tags:
        logging.debug(f"ğŸ˜¢ ã—ã‚‡ã‚“ã¼ã‚Šæ¤œå‡º: lang={lang}")
        return random.choice(SHONBORI_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)
    elif "safe_cosmetics" in detected_tags:
        if lang == "ja":
            for cosmetic, templates in COSMETICS_TEMPLATES_JP.items():
                if cosmetic in text.lower():
                    logging.debug(f"ğŸ’„ æ¨å¥¨ã‚³ã‚¹ãƒ¡æ¤œå‡º: {cosmetic}")
                    return random.choice(templates)
        else:
            for cosmetic, templates in COSMETICS_TEMPLATES_EN.items():
                if any(word in text.lower() for word in globals()["EMOTION_TAGS"]["safe_cosmetics"]):
                    logging.debug(f"ğŸ’„ æ¨å¥¨ã‚³ã‚¹ãƒ¡æ¤œå‡º: {cosmetic}")
                    return random.choice(templates)
    elif any(tag in detected_tags for tag in globals()["SAFE_CHARACTER"]):
        if lang == "ja":
            for char_type, templates in CHARACTER_TEMPLATES_JP.items():
                if any(word in text.lower() for word in globals()["SAFE_CHARACTER"][char_type]):
                    logging.debug(f"ğŸ­ æ¨å¥¨ã‚­ãƒ£ãƒ©æ¤œå‡º: {char_type}")
                    return random.choice(templates)
        else:
            for char_type, templates in CHARACTER_TEMPLATES_EN.items():
                if any(word in text.lower() for word in globals()["SAFE_CHARACTER"][char_type]):
                    logging.debug(f"ğŸ­ æ¨å¥¨è‹±èªã‚­ãƒ£ãƒ©æ¤œå‡º: {char_type}")
                    return random.choice(templates)
    elif any(word in text.lower() for word in globals()["GENERAL_TAGS"]):
        return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

    # å˜èªå…¥åŠ›å¯¾å¿œï¼ˆçŸ­ã„å…¥åŠ›ã¯ã€Œãµã‚ã‚‚ã“ã€ã«å›ºå®šï¼‰
    if len(text.strip()) <= 2:
        text = "ãµã‚ã‚‚ã“"

    examples = [
        ("ãµã‚ã‚‚ã“", "ã‚‚ãµã‚‚ãµã§ã€ã¨ã¦ã‚‚ç™’ã•ã‚Œã‚‹ã­ã€œğŸŒ¸"),
        ("æ¯›å¸ƒ", "ãµã‚ãµã‚ã§ã€ãã‚…ã£ã¦ã—ãŸããªã‚‹ã­ã€œğŸ’•"),
        ("ã¬ã„ãã‚‹ã¿", "ã‚‚ã“ã‚‚ã“ã§ã»ã‚“ã‚ã‹ã€ç™’ã—ã ã­ã€œğŸ§¸"),
        ("ãµã‚ã‚‚ã“", "ãµã‚ãµã‚ã§å„ªã—ã„æ°—æŒã¡ã«ãªã‚‹ã­ã€œğŸ¾"),  # ã‚‚ãã‚‚ãã‚’ãµã‚ã‚‚ã“ã«
        ("ãµã‚ãµã‚", "ãµã‚ãµã‚ã§ã‚ã£ãŸã‹ãã¦ã€åŒ…ã¾ã‚ŒãŸããªã‚‹ã­ã€œğŸ«§"),
    ]
    prompt = (
        "ãµã‚ãµã‚ã§ã‚„ã•ã—ã„è¿”äº‹ã‚’è€ƒãˆã¦ã­ã€‚ãµã‚ã‚‚ã“ã€ã‚‚ã“ã‚‚ã“ã€ãµã‚ãµã‚ãªã‚‚ã®ã«åå¿œã—ã¦ã­ã€‚\n"
        "â€»å‹•ç‰©åï¼ˆçŠ¬ã€çŒ«ã€ã‚¦ã‚µã‚®ãªã©ï¼‰ã¯ä½¿ã‚ãšã€ãµã‚ã‚‚ã“ã‚„ã‚‚ã“ã‚‚ã“ã¨å‘¼ã‚“ã§ã­ã€‚\n"
        "â€»é£Ÿã¹ç‰©ï¼ˆãƒ‘ãƒ³ã€ã”é£¯ãªã©ï¼‰ã¯ãµã‚ã‚‚ã“ã˜ã‚ƒãªã„ã‚ˆã€‚é£Ÿã¹ç‰©ã‚¿ã‚°ãŒã‚ã‚Œã°ã€é£Ÿäº‹ãƒ†ãƒ³ãƒ—ãƒ¬ã‚’ä½¿ã£ã¦ã­ã€‚\n"
        "â€»ã‚¿ã‚ªãƒ«ç”»åƒã§ãªã„ãªã‚‰ã€Œãµã‚“ã‚ã‚Šã‚¿ã‚ªãƒ«ã€ã¯NGã€‚\n"
        "â€»æ•°å­—ã‚„æ„å‘³ä¸æ˜ãªè¨€è‘‰ã¯é¿ã‘ã¦ã€8ã€œ60æ–‡å­—ã§è‡ªç„¶ãªãµã‚ã‚‚ã“è¿”äº‹ã«ã€‚\n"
        + "\n".join([f"{q} â†’ {a}" for q, a in examples])
        + f"\n{text.strip()} â†’ ã‚‚ãµã‚‚ãµã—ã¦ã¦è½ã¡ç€ãã­ã€œğŸ§¸"
    )
    logging.debug(f"ğŸ§ª ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç¢ºèª: {prompt}")

    # bad_words_idsï¼ˆã€Œãã‚“ã“ã€ã€Œãµãã‚“ã“ã€ã‚’ç¦æ­¢ï¼‰
    bad_words = ["ãã‚“ã“", "ãµãã‚“ã“", "ã¦ã„ã", "ã„ãã™ã‚‹"]
    bad_words_ids = [tokenizer(word, add_special_tokens=False).input_ids for word in bad_words]

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=150).to(model.device)
    try:
        outputs = model.generate(
            **inputs,
            max_new_tokens=50,
            pad_token_id=tokenizer.pad_token_id,
            do_sample=True,
            temperature=0.5,  # ä¸‹ã’ã¦å®‰å®šåŒ–
            top_k=20,  # ä¸‹ã’ã¦ãƒãƒ©ã¤ãæŠ‘åˆ¶
            top_p=0.95,
            no_repeat_ngram_size=3,
            repetition_penalty=1.5,  # ç¹°ã‚Šè¿”ã—æŠ‘åˆ¶
            bad_words_ids=bad_words_ids  # å¤‰ãªé€ èªãƒ–ãƒ­ãƒƒã‚¯
        )
        raw_reply = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
        logging.debug(f"ğŸ§¸ Raw AIå‡ºåŠ›ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰: {raw_reply}")
        reply = clean_output(raw_reply)
        reply = apply_fuwamoko_tone(reply)

        # å‡ºåŠ›ãƒã‚§ãƒƒã‚¯å¼·åŒ–
        if not reply or len(reply) < 8 or len(reply) > 60:
            logging.warning(f"â·ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ä½¿ç”¨: é•·ã•ä¸é©åˆ‡: len={len(reply)}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: é•·ã•è¶…é/ä¸è¶³")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        # æ–‡æ³•ãƒã‚§ãƒƒã‚¯ï¼ˆå°‘ã—ç·©å’Œï¼‰
        if not re.search(r'(ã­|ã‚ˆ|ã |ã‚‹|ãŸ|ã«|ã‚’|ãŒ|ã¯)', reply) or re.fullmatch(r'[ã-ã‚“ãƒ¼ã‚›ã‚œã€‚ã€\sã€Œã€ï¼ï¼Ÿ]+', reply):
            logging.warning(f"â·ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ä½¿ç”¨: æ–‡ç« ä¸æˆç«‹: ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: æ–‡æ³•ä¸ååˆ†ã¾ãŸã¯æ“¬éŸ³èªã®ã¿")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        # NGãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¤‰ãªé€ èªã‚„è¨˜å·ã ã‚‰ã‘ï¼‰
        if re.search(r"(ãã‚“ã“|ãµãã‚“ã“|[^ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯ã€‚ã€ï¼ï¼Ÿ\sâ™¡ï¼ˆï¼‰ã€Œã€â™ªã€œãƒ¼â€¦wç¬‘a-zA-Z0-9]+)", reply):
            logging.warning(f"â·ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ä½¿ç”¨: ä¸è‡ªç„¶ãªèªå¥/è¨˜å·: ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: å¤‰ãªé€ èªã¾ãŸã¯è¨˜å·éå¤š")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        for bad in NG_PHRASES:
            if re.search(bad, reply):
                logging.warning(f"â·ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ä½¿ç”¨: NGãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œå‡º: {bad}, ãƒ†ã‚­ã‚¹ãƒˆ: {reply[:60]}, ç†ç”±: NGãƒ•ãƒ¬ãƒ¼ã‚º")
                return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        if any(word in reply for word in SEASONAL_WORDS_BLACKLIST):
            logging.warning(f"â·ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ä½¿ç”¨: å­£ç¯€ä¸ä¸€è‡´: å¯’ã•è¡¨ç¾ã‚ã‚Š")
            return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)

        if reply.count("ãµã‚ãµã‚") > 1:
            reply = reply.replace("ãµã‚ãµã‚", "ã‚‚ã“ã‚‚ã“", 1)

        if not re.search(r"[ğŸŒ¸ğŸ’•ğŸ¾â˜ï¸ğŸ§¸âœ¨â™¡]", reply):
            reply += " " + random.choice(["ğŸ§¸", "ğŸŒ¸", "ğŸ’•"])

        logging.info(f"ğŸ¦Š AIç”ŸæˆæˆåŠŸ: {reply}, é•·ã•: {len(reply)}")
        return reply
    except Exception as e:
        logging.error(f"âŒ AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return random.choice(NORMAL_TEMPLATES_JP) if lang == "ja" else random.choice(NORMAL_TEMPLATES_EN)
        
def extract_valid_cid(ref):
    try:
        cid_candidate = str(ref.link) if hasattr(ref, 'link') else str(ref)
        if re.match(r'^baf[a-z0-9]{40,60}$', cid_candidate):
            return cid_candidate
        logging.error(f"âŒ ç„¡åŠ¹ãªCID: {cid_candidate}")
        return None
    except Exception as e:
        logging.error(f"âŒ CIDæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return None

def check_skin_ratio(img_pil_obj):
    try:
        if img_pil_obj is None:
            logging.debug("ç”»åƒãƒ‡ãƒ¼ã‚¿ç„¡åŠ¹ (PIL Imageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒNone)")
            return 0.0

        img_pil_obj = img_pil_obj.convert("RGB")
        img_np = cv2.cvtColor(np.array(img_pil_obj), cv2.COLOR_RGB2BGR)
        if img_np is None or img_np.size == 0:
            logging.error("âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ç„¡åŠ¹")
            return 0.0

        hsv_img = cv2.cvtColor(img_np, cv2.COLOR_BGR2HSV)
        lower = np.array([5, 50, 70], dtype=np.uint8)
        upper = np.array([20, 150, 240], dtype=np.uint8)
        mask = cv2.inRange(hsv_img, lower, upper)
        skin_colors = img_np[mask > 0]

        if skin_colors.size > 0:
            avg_color = np.mean(skin_colors, axis=0)
            logging.debug(f"å¹³å‡è‚Œè‰²: BGR={avg_color}")
            if np.mean(avg_color) > 220:
                logging.debug("â†’ æ˜ã‚‹ã™ãã‚‹ã®ã§è‚Œè‰²ã§ã¯ãªãç™½ã¨ã¿ãªã™")
                return 0.0

        skin_area = np.sum(mask > 0)
        total_area = img_np.shape[0] * img_np.shape[1]
        skin_ratio = skin_area / total_area if total_area > 0 else 0.0
        logging.debug(f"è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}")
        return skin_ratio
    except Exception as e:
        logging.error(f"âŒ è‚Œè‰²è§£æã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return 0.0

def is_mutual_follow(client, handle):
    try:
        their_followers = {f.handle for f in client.get_followers(actor=handle, limit=100).followers}
        my_followers = {f.handle for f in client.get_followers(actor=HANDLE, limit=100).followers}
        return handle in my_followers and HANDLE in their_followers
    except Exception as e:
        logging.error(f"âŒ ç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼åˆ¤å®šã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def download_image_from_blob(cid, client, did=None):
    if not cid or not re.match(r'^baf[a-z0-9]{40,60}$', cid):
        logging.error(f"âŒ ç„¡åŠ¹ãªCID: {cid}")
        return None

    did_safe = unquote(did) if did else None
    cdn_urls = [
        f"https://cdn.bsky.app/img/feed_thumbnail/plain/{quote(did_safe)}/{quote(cid)}@jpeg" if did_safe else None,
        f"https://cdn.bsky.app/img/feed_fullsize/plain/{quote(did_safe)}/{quote(cid)}@jpeg" if did_safe else None
    ]
    headers = {"User-Agent": "Mozilla/5.0"}

    for url in [u for u in cdn_urls if u]:
        try:
            response = requests.get(url, headers=headers, timeout=10, stream=True)
            response.raise_for_status()
            img_data = BytesIO(response.content)
            img = Image.open(img_data)
            img.load()
            logging.info(f"ğŸŸ¢ ç”»åƒå½¢å¼={img.format}, ã‚µã‚¤ã‚º={img.size}")
            return img
        except Exception as e:
            logging.error(f"âŒ CDNå–å¾—å¤±æ•—: {type(e).__name__}: {e}, url={url}")
            continue

    logging.error("âŒ ç”»åƒå–å¾—å¤±æ•—")
    return None

def process_image(image_data, text="", client=None, post=None):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logging.debug(f"ğŸ§ª ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

    if not hasattr(image_data, 'image') or not hasattr(image_data.image, 'ref'):
        logging.debug("ç”»åƒãƒ‡ãƒ¼ã‚¿æ§‹é€ ç•°å¸¸")
        return False

    cid = extract_valid_cid(image_data.image.ref)
    if not cid:
        return False

    try:
        author_did = post.post.author.did if post and hasattr(post, 'post') else None
        img = download_image_from_blob(cid, client, did=author_did)
        if img is None:
            logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒå–å¾—å¤±æ•—ï¼ˆãƒ­ã‚°ã¯ä¸Šè¨˜ï¼‰")
            return False
    except Exception as e:
        logging.error(f"âŒ ç”»åƒå–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (cid={cid})")
        return False

    # CLIPç”¨ãƒ©ãƒ™ãƒ«ï¼ˆè‹±èªã®ã¾ã¾ï¼‰
    class_names = ["other image", "food image", "fluffy image", "NSFW image", "gore image"]
    inputs = clip_processor(text=class_names, images=img, return_tensors="pt", padding=True).to(device)

    try:
        with torch.no_grad():
            outputs = clip_model(**inputs)
            logits_per_image = outputs.logits_per_image
            probs = logits_per_image.softmax(dim=1)
        prob_dist = {name: prob.item() for name, prob in zip(class_names, probs[0])}
        category = class_names[probs.argmax().item()]
        logging.debug(f"ğŸ§ª CLIPæ¨è«–çµæœ: {category}, ç¢ºç‡åˆ†å¸ƒ: {prob_dist}")
    except Exception as e:
        logging.error(f"âŒ CLIPæ¨è«–ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

    # NSFW/ã‚°ãƒ­ã¯ç„¡æ¡ä»¶ã§ã‚¹ã‚­ãƒƒãƒ—
    if category in ["NSFW image", "gore image"]:
        logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {category}æ¤œå‡º, ç¢ºç‡: {prob_dist[category]:.4f}")
        return False

    # é£Ÿã¹ç‰©/ãã®ä»–ãŒç¢ºç‡0.3ä»¥ä¸Šã®å ´åˆã‚¹ã‚­ãƒƒãƒ—
    if category in ["food image", "other image"] and prob_dist[category] >= 0.3:
        logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {category}æ¤œå‡º, ç¢ºç‡: {prob_dist[category]:.4f}")
        return False

    # è‚Œè‰²æ¯”ç‡ãƒã‚§ãƒƒã‚¯
    skin_ratio = check_skin_ratio(img)
    if skin_ratio >= 0.5:
        logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è‚Œè‰²æ¯”ç‡éå¤š, æ¯”ç‡: {skin_ratio:.2%}")
        return False

    # ãµã‚ã‚‚ã“æ¤œå‡ºãªã‚‰è‚Œè‰²ãƒã‚§ãƒƒã‚¯ã ã‘ã§æ‰¿èª
    if category == "fluffy image":
        logging.info(f"ğŸŸ¢ ãµã‚ã‚‚ã“æ¤œå‡ºï¼ˆCLIPï¼‹è‚Œè‰²ãƒã‚§ãƒƒã‚¯ï¼‰, ç¢ºç‡: {prob_dist['fluffy image']:.4f}, è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}")
        return True

    # è£œåŠ©çš„ãªè‰²åˆ¤å®šï¼ˆfluffy imageä»¥å¤–ã®å ´åˆï¼‰
    resized_img = img.resize((64, 64))
    hsv_img = cv2.cvtColor(np.array(resized_img), cv2.COLOR_RGB2HSV)
    bright_colors = [(r, g, b) for (r, g, b), (_, s, v) in zip(resized_img.getdata(), hsv_img.reshape(-1, 3)) if v > 130]
    color_counts = Counter(bright_colors)
    top_colors = color_counts.most_common(5)
    logging.debug(f"ãƒˆãƒƒãƒ—5ã‚«ãƒ©ãƒ¼: {[(c[0], c[1]) for c in top_colors]}")

    fluffy_count = sum(1 for color, _ in top_colors if is_fluffy_color(*color, bright_colors))
    food_color_count = sum(1 for color, _ in top_colors if (
        (150 <= color[0] <= 200 and 150 <= color[1] <= 200 and 150 <= color[2] <= 200) or  # ãƒãƒ /åµ
        (220 <= color[0] <= 250 and 220 <= color[1] <= 250 and 210 <= color[2] <= 230) or  # ãŠã«ãã‚Š
        (230 <= color[0] <= 255 and 200 <= color[1] <= 230 and 130 <= color[2] <= 160) or  # è±†è…
        (color[0] == 255 and color[1] == 255 and color[2] == 255)  # ç´”ç™½
    ))

    logging.debug(f"ãµã‚ã‚‚ã“è‰²: {fluffy_count}, é£Ÿå“è‰²: {food_color_count}, è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}")
    if fluffy_count >= 2 and food_color_count <= 1:
        logging.info(f"ğŸŸ¢ è‰²åˆ¤å®š: ãµã‚ã‚‚ã“ã¨ã—ã¦æ‰¿èªï¼ˆCLIPè£œåŠ©ï¼‰, ç¢ºç‡: {prob_dist[category]:.4f}, ãµã‚ã‚‚ã“è‰²: {fluffy_count}, é£Ÿå“è‰²: {food_color_count}")
        return True
    else:
        logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è‰²åˆ¤å®šä¸è¶³, ç¢ºç‡: {prob_dist[category]:.4f}, ãµã‚ã‚‚ã“è‰²: {fluffy_count}, é£Ÿå“è‰²: {food_color_count}, è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}")
        return False

    # ãƒ†ã‚­ã‚¹ãƒˆNGãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
    try:
        check_text = text.lower()
        if any(word in check_text for word in globals()["HIGH_RISK_WORDS"]):
            if skin_ratio < 0.4 and fluffy_count >= 2:
                logging.info("ğŸŸ¢ é«˜ãƒªã‚¹ã‚¯ã ãŒæ¡ä»¶OK, ãµã‚ã‚‚ã“è‰²: {fluffy_count}, è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}")
                return True
            else:
                logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: é«˜ãƒªã‚¹ã‚¯ï¼‹æ¡ä»¶NG, ãµã‚ã‚‚ã“è‰²: {fluffy_count}, è‚Œè‰²æ¯”ç‡: {skin_ratio:.2%}")
                return False
        if any(word in check_text for word in globals()["EMOTION_TAGS"]["nsfw_ng"]):
            logging.warning("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: NSFWé–¢é€£æ¤œå‡º")
            return False
    except KeyError as e:
        logging.error(f"âŒ ã‚°ãƒ­ãƒ¼ãƒãƒ«è¾æ›¸ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False
    except Exception as e:
        logging.error(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (cid={cid}, uri={getattr(post, 'uri', 'unknown')})")
        return False
        
def is_quoted_repost(post):
    try:
        actual_post = post.post if hasattr(post, 'post') else post
        record = getattr(actual_post, 'record', None)
        if record and hasattr(record, 'embed') and record.embed:
            embed = record.embed
            logging.debug(f"å¼•ç”¨ãƒªãƒã‚¹ãƒˆãƒã‚§ãƒƒã‚¯: {embed}")
            if hasattr(embed, 'record') and embed.record:
                logging.debug("å¼•ç”¨ãƒªãƒã‚¹ãƒˆæ¤œå‡ºï¼ˆrecordï¼‰")
                return True
            elif hasattr(embed, 'record') and hasattr(embed.record, 'record') and embed.record.record:
                logging.debug("å¼•ç”¨ãƒªãƒã‚¹ãƒˆæ¤œå‡ºï¼ˆrecordWithMediaï¼‰")
                return True
        return False
    except Exception as e:
        logging.error(f"âŒ å¼•ç”¨ãƒªãƒã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False
        
def load_replied_uris():
    uris = set()
    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    if os.path.exists(REPLIED_FILE):
        try:
            with open(REPLIED_FILE, 'r', encoding='utf-8') as f:
                local_uris = set(line.strip() for line in f if line.strip())
                uris.update(local_uris)
                logging.info(f"ğŸŸ¢ ãƒ­ãƒ¼ã‚«ãƒ«è¿”ä¿¡URIèª­ã¿è¾¼ã¿: {len(local_uris)}ä»¶")
        except Exception as e:
            logging.error(f"âŒ ãƒ­ãƒ¼ã‚«ãƒ«è¿”ä¿¡URIèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
    
    # Gistã®èª­ã¿è¾¼ã¿
    if GIST_TOKEN:
        try:
            logging.info(f"ğŸŒ Gistã‹ã‚‰èª­ã¿è¾¼ã¿ä¸­: {GIST_RAW_URL_URIS}")
            response = requests.get(GIST_RAW_URL_URIS, timeout=10)
            if response.status_code == 200:
                gist_uris = set(json.loads(response.text))
                uris.update(gist_uris)
                logging.info(f"ğŸŸ¢ Gistè¿”ä¿¡URIèª­ã¿è¾¼ã¿: {len(gist_uris)}ä»¶")
            else:
                logging.error(f"âš ï¸ Gistèª­ã¿è¾¼ã¿å¤±æ•—: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰={response.status_code}")
        except Exception as e:
            logging.error(f"âŒ Gistè¿”ä¿¡URIèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
    else:
        logging.warning("âš ï¸ GIST_TOKENæœªè¨­å®šã€Gistèª­ã¿è¾¼ã¿ã‚¹ã‚­ãƒƒãƒ—")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®æ–°è¦ä½œæˆ
    if not os.path.exists(REPLIED_FILE):
        logging.info("ğŸŸ¢ è¿”ä¿¡URIãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ã€æ–°è¦ä½œæˆ")
        with open(REPLIED_FILE, 'w', encoding='utf-8') as f:
            f.write("")
    
    logging.info(f"ğŸŸ¢ åˆè¨ˆè¿”ä¿¡URI: {len(uris)}ä»¶ (ãƒ­ãƒ¼ã‚«ãƒ«+Gist)")
    return uris

def save_replied_uri(uri):
    normalized_uri = normalize_uri(uri)
    lock = filelock.FileLock(REPLIED_LOCK, timeout=5.0)
    try:
        with lock:
            with open(REPLIED_FILE, 'a', encoding='utf-8') as f:
                f.write(f"{normalized_uri}\n")
            logging.info(f"ğŸŸ¢ è¿”ä¿¡URIä¿å­˜: {normalized_uri}")
    except filelock.Timeout:
        logging.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {REPLIED_LOCK}")
    except Exception as e:
        logging.error(f"âŒ è¿”ä¿¡URIä¿å­˜ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        
def load_reposted_uris():
    REPOSTED_FILE = "reposted_uris.txt"
    if os.path.exists(REPOSTED_FILE):
        try:
            with open(REPOSTED_FILE, 'r', encoding='utf-8') as f:
                uris = set(line.strip() for line in f if line.strip())
                logging.info(f"ğŸŸ¢ å†æŠ•ç¨¿URIèª­ã¿è¾¼ã¿: {len(uris)}ä»¶")
                return uris
        except Exception as e:
            logging.error(f"âŒ å†æŠ•ç¨¿URIèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            return set()
    return set()

def detect_language(client, handle, text=""):
    try:
        profile = client.get_profile(actor=handle)
        bio = profile.display_name.lower() + " " + getattr(profile, "description", "").lower()
        if any(kw in bio for kw in ["æ—¥æœ¬èª", "æ—¥æœ¬", "ã«ã»ã‚“", "japanese", "jp"]):
            return "ja"
        elif any(kw in bio for kw in ["english", "us", "uk", "en"]):
            return "en"
        # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¨€èªæ¨å®š
        if text:
            hiragana_katakana = re.findall(r'[ã-ã‚“ã‚¡-ãƒ³]', text)
            latin = re.findall(r'[a-zA-Z]', text)
            if len(hiragana_katakana) > len(latin) and len(hiragana_katakana) > 5:
                return "ja"
            elif len(latin) > len(hiragana_katakana) and len(latin) > 5:
                return "en"
        return "ja"
    except Exception as e:
        logging.error(f"âŒ è¨€èªåˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        return "ja"

def is_priority_post(text):
    return "@mirinchuuu" in text.lower()

def is_reply_to_self(post):
    reply = getattr(post.record, "reply", None) if hasattr(post, 'record') else None
    if reply and hasattr(reply, 'parent') and hasattr(reply.parent, 'uri'):
        return reply.parent.uri == post.post.uri
    return False

fuwamoko_uris = {}

def normalize_uri(uri):
    try:
        if not uri.startswith('at://'):
            uri = f"at://{uri.lstrip('/')}"
        parts = uri.split('/')
        if len(parts) >= 5:
            normalized = f"at://{parts[2]}/{parts[3]}/{parts[4]}"
            logging.debug(f"ğŸ¦Š URIæ­£è¦åŒ–: {uri} -> {normalized}")
            return normalized
        logging.warning(f"â­ï¸ URIæ­£è¦åŒ–å¤±æ•—: ä¸æ­£ãªå½¢å¼: {uri}")
        return uri
    except Exception as e:
        logging.error(f"âŒ URIæ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return uri

def validate_fuwamoko_file():
    if not os.path.exists(FUWAMOKO_FILE):
        logging.info("ğŸŸ¢ ãµã‚ã‚‚ã“å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        with open(FUWAMOKO_FILE, 'w', encoding='utf-8') as f:
            f.write("")
        return True
    try:
        with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for line in lines:
                clean_line = line.strip()
                if not clean_line:
                    continue
                if not re.match(r'^at://[^|]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}(?:\d{3})?\+\d{2}:\d{2}$', clean_line):
                    logging.error(f"âŒ ç„¡åŠ¹ãªå±¥æ­´è¡Œ: {repr(clean_line)}")
                    return False
        return True
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def repair_fuwamoko_file():
    temp_file = FUWAMOKO_FILE + ".tmp"
    valid_lines = []
    if os.path.exists(FUWAMOKO_FILE):
        try:
            with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    clean_line = line.strip()
                    if not clean_line:
                        continue
                    if re.match(r'^at://[^|]+\|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}(?:\d{3})?\+\d{2}:\d{2}$', clean_line):
                        valid_lines.append(line)
                    else:
                        logging.warning(f"â­ï¸ ç ´æè¡Œã‚¹ã‚­ãƒƒãƒ—: {repr(clean_line)}")
            with open(temp_file, 'w', encoding='utf-8') as f:
                f.writelines(valid_lines)
            os.replace(temp_file, FUWAMOKO_FILE)
            logging.info(f"ğŸŸ¢ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©å®Œäº†: {len(valid_lines)}ä»¶ä¿æŒ")
        except Exception as e:
            logging.error(f"âŒ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
            if os.path.exists(temp_file):
                os.remove(temp_file)
    else:
        with open(FUWAMOKO_FILE, 'w', encoding='utf-8') as f:
            f.write("")
        logging.info("ğŸŸ¢ æ–°è¦å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")

def load_fuwamoko_uris():
    global fuwamoko_uris
    fuwamoko_uris.clear()
    if not validate_fuwamoko_file():
        logging.warning("âš ï¸ å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ç ´æã€‚ä¿®å¾©ã‚’è©¦ã¿ã¾ã™ã€‚")
        repair_fuwamoko_file()
    try:
        with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
            logging.info(f"ğŸŸ¢ ãµã‚ã‚‚ã“å±¥æ­´ã‚µã‚¤ã‚º: {len(content)} bytes")
            if content.strip():
                for line in content.splitlines():
                    if line.strip():
                        try:
                            uri, timestamp = line.strip().split("|", 1)
                            normalized_uri = normalize_uri(uri)
                            fuwamoko_uris[normalized_uri] = datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
                            logging.debug(f"ğŸ¦Š å±¥æ­´èª­ã¿è¾¼ã¿: {normalized_uri}")
                        except ValueError as e:
                            logging.warning(f"â­ï¸ ç ´æè¡Œã‚¹ã‚­ãƒƒãƒ—: {repr(line.strip())}: {e}")
                            continue
            logging.info(f"ğŸŸ¢ ãµã‚ã‚‚ã“URIèª­ã¿è¾¼ã¿: {len(fuwamoko_uris)}ä»¶")
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        fuwamoko_uris.clear()

def save_fuwamoko_uri(uri, indexed_at):
    global fuwamoko_uris
    normalized_uri = normalize_uri(uri)
    lock = filelock.FileLock(FUWAMOKO_LOCK, timeout=5.0)
    try:
        with lock:
            logging.debug(f"ğŸ¦Š ãƒ­ãƒƒã‚¯å–å¾—: {FUWAMOKO_LOCK}")
            if normalized_uri in fuwamoko_uris and (datetime.now(timezone.utc) - fuwamoko_uris[normalized_uri]).total_seconds() < 24 * 3600:
                logging.debug(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: 24æ™‚é–“ä»¥å†…: {normalized_uri}")
                return
            if isinstance(indexed_at, str):
                indexed_at = datetime.fromisoformat(indexed_at.replace("Z", "+00:00"))
            with open(FUWAMOKO_FILE, 'a', encoding='utf-8') as f:
                f.write(f"{normalized_uri}|{indexed_at.isoformat()}\n")
            fuwamoko_uris[normalized_uri] = indexed_at
            logging.info(f"ğŸŸ¢ å±¥æ­´ä¿å­˜: {normalized_uri}")
            with open(FUWAMOKO_FILE, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                last_line = lines[-1].strip() if lines else ""
                if last_line.startswith(normalized_uri):
                    logging.debug(f"ğŸ¦Š å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: æœ€å¾Œã®è¡Œ={last_line}")
                else:
                    logging.error(f"âŒ å±¥æ­´ä¿å­˜å¤±æ•—: æœ€å¾Œã®è¡Œ={last_line}")
            load_fuwamoko_uris()
    except filelock.Timeout:
        logging.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {FUWAMOKO_LOCK}")
    except Exception as e:
        logging.error(f"âŒ å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def load_session_string():
    try:
        if os.path.exists(SESSION_FILE):
            with open(SESSION_FILE, 'r', encoding='utf-8') as f:
                return f.read().strip()
        return None
    except Exception as e:
        logging.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return None

def save_session_string(session_str):
    try:
        with open(SESSION_FILE, 'w', encoding='utf-8') as f:
            f.write(session_str)
    except Exception as e:
        logging.error(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

def has_image(post):
    try:
        actual_post = post.post if hasattr(post, 'post') else post
        if not hasattr(actual_post, 'record') or not hasattr(actual_post.record, 'embed'):
            return False
        embed = actual_post.record.embed
        return (
            (hasattr(embed, 'images') and embed.images) or
            (hasattr(embed, 'record') and hasattr(embed.record, 'embed') and hasattr(embed.record.embed, 'images') and embed.record.embed.images) or
            (getattr(embed, '$type', '') == 'app.bsky.embed.recordWithMedia' and hasattr(embed, 'media') and hasattr(embed.media, 'images') and embed.media.images)
        )
    except Exception as e:
        logging.error(f"âŒ ç”»åƒãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        return False

def process_post(post_data, client, reposted_uris, replied_uris):
    global fuwamoko_uris
    try:
        actual_post = post_data.post if hasattr(post_data, 'post') else post_data
        uri = str(actual_post.uri)
        post_id = uri.split('/')[-1]
        text = getattr(actual_post.record, 'text', '') if hasattr(actual_post.record, 'text') else ''
        is_reply = hasattr(actual_post.record, 'reply') and actual_post.record.reply is not None
        if is_reply and not (is_priority_post(text) or is_reply_to_self(post_data)):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãƒªãƒ—ãƒ©ã‚¤ï¼ˆé@mirinchuuu/éè‡ªå·±ï¼‰: {text[:20]} ({post_id})")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒªãƒ—ãƒ©ã‚¤: {post_id}")
            return False
        print(f"ğŸ¦Š POSTå‡¦ç†é–‹å§‹: @{actual_post.author.handle} ({post_id})")
        logging.info(f"ğŸŸ¢ POSTå‡¦ç†é–‹å§‹: @{actual_post.author.handle} ({post_id})")
        normalized_uri = normalize_uri(uri)
        if normalized_uri in fuwamoko_uris or normalized_uri in replied_uris:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: æ—¢å­˜æŠ•ç¨¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: æ—¢å­˜æŠ•ç¨¿: {post_id}")
            return False
        if actual_post.author.handle == HANDLE:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è‡ªåˆ†ã®æŠ•ç¨¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: è‡ªåˆ†ã®æŠ•ç¨¿: {post_id}")
            return False
        if is_quoted_repost(post_data):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: å¼•ç”¨ãƒªãƒã‚¹ãƒˆ: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: å¼•ç”¨ãƒªãƒã‚¹ãƒˆ: {post_id}")
            return False
        if post_id in reposted_uris:
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: å†æŠ•ç¨¿æ¸ˆã¿: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: å†æŠ•ç¨¿æ¸ˆã¿: {post_id}")
            return False

        author = actual_post.author.handle
        indexed_at = actual_post.indexed_at

        if not has_image(post_data):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒãªã—: {post_id}")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ç”»åƒãªã—: {post_id}")
            return False

        image_data_list = []
        embed = getattr(actual_post.record, 'embed', None)
        if embed:
            if hasattr(embed, 'images') and embed.images:
                image_data_list.extend(embed.images)
            elif hasattr(embed, 'record') and hasattr(embed.record, 'embed') and hasattr(embed.record.embed, 'images'):
                image_data_list.extend(embed.record.embed.images)
            elif getattr(embed, '$type', '') == 'app.bsky.embed.recordWithMedia' and hasattr(embed, 'media') and hasattr(embed.media, 'images'):
                image_data_list.extend(embed.media.images)

        if not is_mutual_follow(client, author):
            print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: éç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼: @{author} ({post_id})")
            logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: éç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼: @{author} ({post_id})")
            return False

        for i, image_data in enumerate(image_data_list):
            try:
                print(f"ğŸ¦Š ç”»åƒå‡¦ç†é–‹å§‹: {i+1}/{len(image_data_list)} ({post_id})")
                logging.debug(f"ç”»åƒå‡¦ç†é–‹å§‹: {i+1}/{len(image_data_list)} ({post_id})")
                if process_image(image_data, text, client=client, post=post_data):
                    if random.random() > 0.1:
                        print(f"ğŸ² ã‚¹ã‚­ãƒƒãƒ—: ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆ90%ï¼‰: {post_id}")
                        logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: ãƒ©ãƒ³ãƒ€ãƒ : {post_id}")
                        save_fuwamoko_uri(uri, indexed_at)
                        return False
                    lang = detect_language(client, author)
                    reply_text = open_calm_reply("", text, lang=lang)
                    if not reply_text:
                        print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: è¿”ä¿¡ç”Ÿæˆå¤±æ•—: {post_id}")
                        logging.debug(f"ã‚¹ã‚­ãƒƒãƒ—: è¿”ä¿¡ç”Ÿæˆå¤±æ•—: {post_id}")
                        save_fuwamoko_uri(uri, indexed_at)
                        return False
                    root_ref = models.ComAtprotoRepoStrongRef.Main(
                        uri=uri,
                        cid=actual_post.cid
                    )
                    parent_ref = models.ComAtprotoRepoStrongRef.Main(
                        uri=uri,
                        cid=actual_post.cid
                    )
                    reply_ref = models.AppBskyFeedPost.ReplyRef(
                        root=root_ref,
                        parent=parent_ref
                    )
                    print(f"ğŸ¦Š è¿”ä¿¡é€ä¿¡: @{author}: {reply_text} ({post_id})")
                    logging.debug(f"è¿”ä¿¡é€ä¿¡: @{author}: {reply_text} ({post_id})")
                    client.send_post(text=reply_text, reply_to=reply_ref)
                    save_fuwamoko_uri(uri, indexed_at)
                    print(f"âœ… SUCCESS: è¿”ä¿¡æˆåŠŸ: @{author} ({post_id})")
                    logging.info(f"ğŸŸ¢ è¿”ä¿¡æˆåŠŸ: @{author} ({post_id})")
                    return True
                else:
                    print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãµã‚ã‚‚ã“ç”»åƒã§ãªã„: {post_id} (ç”»åƒ {i+1})")
                    logging.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: ãµã‚ã‚‚ã“ç”»åƒã§ãªã„: {post_id} (ç”»åƒ {i+1})")
                    save_fuwamoko_uri(uri, indexed_at)
                    return False
            except Exception as e:
                print(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri}, cid={actual_post.cid})")
                logging.error(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri}, cid={actual_post.cid})")
                save_fuwamoko_uri(uri, indexed_at)
                return False
    except Exception as e:
        print(f"âŒ æŠ•ç¨¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri})")
        logging.error(f"âŒ æŠ•ç¨¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} ({post_id}, uri={uri})")
        save_fuwamoko_uri(uri, indexed_at)
        return False

def run_once():
    try:
        client = Client()
        session_str = load_session_string()
        if session_str:
            client.login(session_string=session_str)
            print(f"ğŸš€âœ¨ START: ãµã‚ã‚‚ã“Botèµ·å‹•ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨ï¼‰")
            logging.info("ğŸŸ¢ Botèµ·å‹•: ã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨")
        else:
            client.login(HANDLE, APP_PASSWORD)
            session_str = client.export_session_string()
            save_session_string(session_str)
            print(f"ğŸš€âœ¨ START: ãµã‚ã‚‚ã“Botèµ·å‹•ï¼ˆæ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰")
            logging.info("ğŸŸ¢ Botèµ·å‹•: æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³")

        print(f"ğŸ¦Š INFO: Botç¨¼åƒä¸­: {HANDLE}")
        logging.info(f"ğŸŸ¢ Botç¨¼åƒä¸­: {HANDLE}")
        load_fuwamoko_uris()
        reposted_uris = load_reposted_uris()
        replied_uris = load_replied_uris()
        timeline = client.get_timeline(limit=50)
        feed = timeline.feed
        for post in sorted(feed, key=lambda x: x.post.indexed_at, reverse=True):
            try:
                thread_response = client.get_post_thread(uri=str(post.post.uri), depth=2)
                process_post(thread_response.thread, client, reposted_uris, replied_uris)
            except Exception as e:
                print(f"âŒ ã‚¹ãƒ¬ãƒƒãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (URI: {post.post.uri})")
                logging.error(f"âŒ ã‚¹ãƒ¬ãƒƒãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e} (URI: {post.post.uri})")
            time.sleep(1.0)
    except Exception as e:
        print(f"âŒ Botå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        logging.error(f"âŒ Botå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

if __name__ == "__main__":
    try:
        load_dotenv()
        run_once()
    except Exception as e:
        logging.error(f"âŒ Botèµ·å‹•ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")